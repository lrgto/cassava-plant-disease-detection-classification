\section{Discussion}
\label{Disscussion}

Our original aims were to explore various classification techniques on a feasible data set were not met, hindered by the model's power requirement. This led to the group looking at ways to further improve the model, keeping in line with the originally proposed cognitive neural network, we looked decreasing the runtime by experimenting with the filters, layers. This was a crux in this group as the power requirements of the GPU were too high, we were able to run 1-10 epochs fine however theoretically the more epochs, the better the test accuracy, a group member had to use and external python web server to run the model efficiently allowing the group to obtain good results. The main issue that arose was that the runtime was too great and when we manage to fix that issue we ran out of time to properly explore the neural network to its fullest capacity. Further improvements would be to explore different classifiers as its apparent that that the CNN classifier has a strict computer requirement. We disregarded the decision trees classifier due to the inaccuracies that is achieves in this type of model and potentially random forests too ass its based off of a true or false algorithm and may disregard key data within the image too soon. 

\section{Conclusion}
\label{Conclusion}

As a group we created various models and completed a variety of tests on these models with the main aim of improving accuracy for the testing set. We adjusted the epochs, we changed the shape of the model, the sizes of the images and augmented the images that were being read into the model. The aim was to find the best of all changes to eventually see how they worked together to end up with the best model we could for the Cassava data set, with a peak accuracy of 67\% we feel that whilst it could be improved, for the size of the data set and the number of classifiers required of it that this result is very good. The images are complex and very large to start with so for a model with around 100 epochs to get a result like this was a good step forward and shows that perhaps with more changes to the data set, perhaps by flipping images along the vertical, we could have achieved an accuracy closer to 80\% with more epochs to train the model. With the Cognitive Neural Network model, training the 2d convolutional layers separately from the dense layer allowed the system to train not just faster but it improved the test accuracy up to 63\% which is the highest we've managed to get. The system however requires a lot of power to run the model and we confidently feel that the we have improved this model.
